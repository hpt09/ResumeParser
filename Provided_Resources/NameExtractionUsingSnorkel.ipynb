{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snorkel.labeling import labeling_function\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv(r\"df_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize as st\n",
    "\n",
    "df_token_sentence = pd.DataFrame(columns=None)\n",
    "\n",
    "df_token_sentence = df_dev.apply(lambda row: st(row['content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token_sentence.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token_sentence.to_csv(r\"df_token_sentence.csv\", header=['content'], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.read_csv(r\"df_token_sentence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = False\n",
    "df = df_ts\n",
    "column = 'content'\n",
    "sep = ','\n",
    "indexes = list()\n",
    "new_values = list()\n",
    "df = df.dropna(subset=[column])\n",
    "for i, presplit in enumerate(df[column].astype(str)):\n",
    "    values = presplit.split(sep)\n",
    "    if keep and len(values) > 1:\n",
    "        indexes.append(i)\n",
    "        new_values.append(presplit)\n",
    "    for value in values:\n",
    "        indexes.append(i)\n",
    "        new_values.append(value)\n",
    "new_df = df.iloc[indexes, :].copy()\n",
    "new_df[column] = new_values\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(r\"tokenized_sentences.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy = pd.read_csv(r\"tokenized_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_spacy['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punct = df_spacy['content'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy = df_spacy[df_spacy.content!=remove_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_spacy.head(5))\n",
    "print(len(df_spacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy.to_csv(r\"1st_level_cleaned_sentences.csv\", index=False, header=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy = pd.read_csv(\"1st_level_cleaned_sentences.csv\")\n",
    "df_spacy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\",\"\")\n",
    "    text = text.replace(\".\",\"\")\n",
    "    return text\n",
    "\n",
    "df_spacy['content']= df_spacy['content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy.to_csv(\"cleaned_sentences.csv\", index=False, header=['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Extraction using Snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snorkel.labeling import labeling_function\n",
    "import nltk\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy = pd.read_csv(r\"cleaned_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import sent_tokenize as st\n",
    "\n",
    "# temp = df_spacy['content'][0]\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# text = nlp(temp)\n",
    "\n",
    "# for ent in text.ents:\n",
    "#     print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "POSITIVE = 1\n",
    "NEGATIVE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @labeling_function()\n",
    "# def lf_start_of_resume(x):\n",
    "#     print(x)\n",
    "#     return POSITIVE if len(x)<4 else NEGATIVE\n",
    "        \n",
    "\n",
    "\n",
    "# @labeling_function()\n",
    "# def lf_start_of_resume1(x):\n",
    "#     print(x)\n",
    "#     return POSITIVE if len(x)<4 else NEGATIVE\n",
    "\n",
    "    \n",
    "# @labeling_function()\n",
    "# def lf_start_of_resume2(x):\n",
    "#     print(x)\n",
    "#     return POSITIVE if len(x)<4 else NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_name_extraction(x):\n",
    "    x = x.to_string()\n",
    "    places_list=['Karnataka', 'Bangalore', 'Tamil Nadu', 'Kanpur','Noida', 'Gujarat', 'Haryana', 'Bengaluru', 'Uttar Pradesh', 'Kolhapur', 'Kerala' ,'Maharashtra']\n",
    "    \n",
    "    ners = nlp(x)\n",
    "    for ent in ners.ents:\n",
    "        if(ent.label_ == \"PERSON\"):\n",
    "            for place in places_list:\n",
    "                if(x.find(place)!=-1):\n",
    "#                     print(\"negative:\", \"x:\", x, \"place:\", place)\n",
    "                    return NEGATIVE\n",
    "            if(len(x)<20 or len(x)>35):\n",
    "#                 print(\"negative: length\", len(x), x)\n",
    "                return NEGATIVE\n",
    "            else:\n",
    "#                 print(\"positive:\", x, len(x))\n",
    "                return POSITIVE\n",
    "        elif(ent.label_ !=\"PERSON\"):\n",
    "            return NEGATIVE\n",
    "#     print(\"abstain:\", x, len(x))\n",
    "    return ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_temp1(x):\n",
    "    return ABSTAIN\n",
    "    \n",
    "@labeling_function()\n",
    "def lf_temp2(x):\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel, PandasLFApplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [lf_name_extraction,lf_temp1,lf_temp2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lfs = [lf_start_of_resume,lf_start_of_resume1,lf_start_of_resume2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "applier = PandasLFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 69478/69478 [15:31<00:00, 74.60it/s]\n"
     ]
    }
   ],
   "source": [
    "L_train = applier.apply(df_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_dev = pd.read_csv(r\"Y_dev.csv\").as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFAnalysis(L_dev,lfs).lf_summary(Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model = LabelModel(cardinality=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model.fit(L_train, n_epochs=500, log_freq=50, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy[\"label\"] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2       -1\n",
       "3       -1\n",
       "4       -1\n",
       "        ..\n",
       "69473   -1\n",
       "69474   -1\n",
       "69475   -1\n",
       "69476    1\n",
       "69477   -1\n",
       "Name: label, Length: 69478, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy.to_csv(path_or_buf = 'snorkel_labeled.csv',index=False)\n",
    "df_spacy = df_spacy[df_spacy.label != ABSTAIN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = df_spacy.content.tolist()\n",
    "cv = CountVectorizer(ngram_range=(1,2)).fit(train_text)\n",
    "X_train = cv.transform(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver=\"newton-cg\")\n",
    "clf = clf.fit(X=X_train, y=df_spacy.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r'test_files\\test_tokenized_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rahul Kumar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fresher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karnataka - Email me on Indeed: indeedcom/r/R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking for a challenging carrier to enhance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>in final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>Aff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>To CCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>https://wwwindeedcom/r/Vijat-Kumar/0e4c2eea28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content\n",
       "0                                           Rahul Kumar\n",
       "1                                               Fresher\n",
       "2                                             Bengaluru\n",
       "3      Karnataka - Email me on Indeed: indeedcom/r/R...\n",
       "4      Looking for a challenging carrier to enhance ...\n",
       "...                                                 ...\n",
       "2476                                           in final\n",
       "2477                                                Aff\n",
       "2478                                             To CCS\n",
       "2479                                         University\n",
       "2480   https://wwwindeedcom/r/Vijat-Kumar/0e4c2eea28...\n",
       "\n",
       "[2481 rows x 1 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test.content.tolist()\n",
    "T_train = cv.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = clf.predict(X=T_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "2476    0\n",
       "2477    0\n",
       "2478    0\n",
       "2479    0\n",
       "2480    0\n",
       "Name: prediction, Length: 2481, dtype: int32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_files\\snorkel_test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv(r\"cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_cleaned['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Afreen Jamadar\n",
       "1      Alok Khandai\n",
       "2       Anvitha Rao\n",
       "3          arjun ks\n",
       "4     Arun Elumalai\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df_spacy[df_spacy['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afreen Jamadar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Alok Khandai</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Anvitha Rao</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Ashalata Bisoyi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Ashok Kunam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             content  label\n",
       "0     Afreen Jamadar      1\n",
       "46      Alok Khandai      1\n",
       "243      Anvitha Rao      1\n",
       "524  Ashalata Bisoyi      1\n",
       "578      Ashok Kunam      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positive.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arjun ks\n",
      "Arun Elumalai\n",
      "Ayesha B\n",
      "Darshan G.\n",
      "Govardhana K\n",
      "Ijas Nizamuddin\n",
      "Karthihayini C\n",
      "Kavitha K\n",
      "Kavya U.\n",
      "kimaya sonawane\n",
      "Mohamed Ameen\n",
      "Nitin Tr\n",
      "Pradeeba V\n",
      "PRASHANTH BADALA\n",
      "Pratibha P\n",
      "Prem Koshti\n",
      "Ram Edupuganti\n",
      "Ramesh HP\n",
      "Ramya. P\n",
      "R Arunravi\n",
      "Sai Dhir\n",
      "Sameer Kujur\n",
      "Shabnam Saba\n",
      "Shaheen Unissa\n",
      "Shreyanshu Gupta\n",
      "Soumya Balan\n",
      "Syam Devendla\n",
      "Vamsi krishna\n",
      "VARUN AHLUWALIA\n",
      "Vijayalakshmi Govindarajan\n",
      "Yasothai Jayaramachandran\n",
      "Yathishwaran P\n",
      "amarjyot sodhi\n",
      "Sameer Kujur\n",
      "Abdul B\n",
      "Ramesh chokkala\n",
      "Ganesh AlalaSundaram\n",
      "Bangalore Tavarekere\n",
      "Tanmoy Maity\n",
      "Chhaya Prabhale\n",
      "Karthik G V\n",
      "Soumya Balan\n",
      "Akshay Dubey\n",
      "B. Gokul\n",
      "Anand S\n",
      "Priyesh Dubey\n",
      "Laya A\n",
      "Vishwanath P\n",
      "Ramakrishna Rao\n",
      "Keshav Dhawale\n",
      "Gunjan Nayyar\n",
      "Rupesh Reddy\n",
      "Puneeth R\n",
      "Deepika S\n",
      "Georgia Institute of Technology\n",
      "Shaik Tazuddin\n",
      "Angad Waghmare\n",
      "Tapan kumar Nayak\n",
      "Palani S\n",
      "Mayank Shukla\n",
      "Sridevi H\n",
      "Raktim Podder\n",
      "Pavithra M\n",
      "shrikant desai\n",
      "K. Siddharth\n",
      "Venkateswara D\n",
      "Siddharth Choudhary\n",
      "Pradeep Kumar\n",
      "Ajay Gupta\n",
      "sneh jain\n",
      "Rahul singh\n",
      "sneh jain\n",
      "Ram Dubey\n",
      "MUKESH SHAH\n",
      "Ram Dubey\n",
      "Rajesh Rokaya\n",
      "Nitesh Raheja\n",
      "RIYAZ SHAIKH\n",
      "Satyendra Singh\n",
      "Tahir Pasa\n",
      "Priyanka Sonar\n",
      "Satyendra Singh\n",
      "aaryan vatts\n",
      "Pranav Samant\n",
      "Satish Patil\n",
      "Manoj Chawla\n",
      "Harpreet Kaur Lohiya\n",
      "Reshma Raeen\n",
      "Mahesh. Shrigiri\n",
      "Rajesh Rokaya\n",
      "Swapna Sanadi\n",
      "Nilesh Sinha\n",
      "Vikram Rajput\n",
      "Pranav Samant\n",
      "AMIT DUBEY\n",
      "Rajesh Davankar\n",
      "Shrikant V\n",
      "Harpreet Kaur Lohiya\n",
      "MUKESH SHAH\n",
      "Harinath Rudra\n",
      "Shailesh Jadhav\n",
      "Mayur Talele\n",
      "Punit Raghav\n",
      "Punit Raghav\n",
      "Pradyuman Nayyar\n",
      "Sameer More\n",
      "Prashant Chitare\n",
      "Amrata Rajani\n",
      "Ravi Shahade\n",
      "Neha Lakhanpal\n",
      "Kuntal Dandir\n",
      "Prembahadur Kamal\n",
      "Shreyas Chippalkatti\n",
      "Naynish Argade\n",
      "Sameer More\n",
      "Mahesh Chalwadi\n",
      "Hardik Shah\n",
      "Raunak dambir Dambir\n",
      "manoj singh\n",
      "Lokesh Inarkar\n",
      "Jameel Pathan\n",
      "Tarun Chhag\n",
      "AARTI MHATRE\n",
      "Mahesh. Shrigiri\n",
      "SUFIYAN Motiwala\n",
      "arjun ks\n",
      "Arun Elumalai\n",
      "Ayesha B\n",
      "Darshan G.\n",
      "Govardhana K\n",
      "Ijas Nizamuddin\n",
      "Karthihayini C\n",
      "Kavitha K\n",
      "Kavya U.\n",
      "kimaya sonawane\n",
      "Mohamed Ameen\n",
      "Nitin Tr\n",
      "Pradeeba V\n",
      "PRASHANTH BADALA\n",
      "Ram Edupuganti\n",
      "Ramesh HP\n",
      "Ramya. P\n",
      "R Arunravi\n",
      "Sai Dhir\n",
      "Sameer Kujur\n",
      "Shabnam Saba\n",
      "Shaheen Unissa\n",
      "Shreyanshu Gupta\n",
      "Soumya Balan\n",
      "Vijayalakshmi Govindarajan\n",
      "Sameer Kujur\n",
      "Abdul B\n",
      "Shreekumar Das\n",
      "Pradeep R shukla Shukla\n",
      "Laxmiprasad Ukidawe\n",
      "Siddhanth Jaisinghani\n",
      "Adil K\n",
      "Ashwini Vartak\n",
      "Adil K\n",
      "AARTI MHATRE\n",
      "H.N Arun Kumar\n",
      "Naynish Argade\n",
      "Sandeep Mahadik\n",
      "Jitendra. Makhijani\n",
      "Sameer Gavad\n",
      "shish Dubey\n",
      "Bikram Bhattacharjee\n",
      "Nadeem Sayyed\n",
      "Maharashtra\n",
      "Mahesh Gokral\n",
      "Tarun Chhag\n",
      "Vikram Hirugade\n",
      "k.balaji krishnamoorthy\n",
      "Mohd. Chaman\n",
      "D.ALDRIN DAVID\n",
      "Hemant Tupe\n",
      "Rohit Solanki\n",
      "Abhijeet Srivastava\n",
      "Gautam Palit\n",
      "Pankti Patel\n",
      "Vivek Mishra\n",
      "Karthihayini C\n",
      "VARUN AHLUWALIA\n",
      "Raktim Podder\n",
      "Pavithra M\n",
      "shrikant desai\n",
      "Tahir Pasa\n",
      "Punit Raghav\n",
      "Tarun Chhag\n",
      "Aditi Solanki\n",
      "Anirban Ghosh\n",
      "Arunbalaji. R\n",
      "Nitin Tr\n",
      "Mayank Shukla\n",
      "shrikant desai\n",
      "Adil K\n",
      "Pankti Patel\n",
      "aaryan vatts\n",
      "Shaheen Unissa\n",
      "Kuntal Dandir\n",
      "Anil Jinsi\n",
      "Gaurav Swami\n",
      "Kuntal Dandir\n",
      "Anil Jinsi\n",
      "Lucky Aneja\n",
      "rajeev nigam\n",
      "manoj singh\n",
      "Abheek Chatterjee\n",
      "B. Varadarajan\n",
      "Tarak.H. Joshi\n",
      "Chandrashekhar javalkote\n",
      "Niranjan Tambade\n",
      "Adil K\n",
      "Kalpesh Shah\n",
      "Yuvaraj Balakrishnan\n",
      "ASHWINI DASARI\n",
      "Prosenjit Mitra\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for name in df_label:\n",
    "#     name = name.to_string()\n",
    "    if(df_positive.content.to_string().find(name)!=-1):\n",
    "        count +=1\n",
    "    else:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449\n"
     ]
    }
   ],
   "source": [
    "print(count) #Only 449 names were identified out of 667 names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.31634182908546\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", count/667*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"TIBCO Administrator 560\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abstain_names = pd.read_csv('abstain_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_abstain_names.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_count = 0\n",
    "total_names = df_abstain_names.shape\n",
    "for name in df_abstain_names['names']:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(name)\n",
    "    for ent in doc.ents:\n",
    "        identified_count +=1\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "print(\"No.of Identified Names: \", identified_count)\n",
    "print(\"No.of unidentified Names: \", total_names-identified_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snorkel-env",
   "language": "python",
   "name": "snorkel-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
